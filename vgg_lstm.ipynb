{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n",
    "from operator import itemgetter \n",
    "from random import shuffle \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "y_list = []\n",
    "\n",
    "# load the binary files and add target variables\n",
    "for class_n, c in enumerate(['kiss', 'handshake', 'hug', 'highfive']):\n",
    "    f = os.listdir('output/'+c)\n",
    "    f = list(map(lambda x: 'output/'+c+'/'+x, f))\n",
    "    \n",
    "    filtered = list(filter(lambda x: x.split('.')[-1] == 'npy', f))\n",
    "\n",
    "    # only get first 50 samples (so not to interfere with augmented samples)\n",
    "    filtered.sort(key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "    filtered = filtered[:50]\n",
    "\n",
    "    y_list.extend([class_n]*len(filtered))\n",
    "    files.extend(filtered)\n",
    "\n",
    "y = np.array(y_list)\n",
    "\n",
    "# scale data to [0, 1] range\n",
    "x = [np.load(x)/255 for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0].dtype)\n",
    "assert len(x) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, test_size=0.1):\n",
    "    shuffled_idx = np.random.permutation(len(X))\n",
    "    \n",
    "    split_at = int(len(shuffled_idx) * test_size)\n",
    "    train_idx = shuffled_idx[split_at:]\n",
    "    test_idx = shuffled_idx[:split_at]\n",
    "    \n",
    "    #TODO: add use of one-hot encoding\n",
    "    onehot = np.zeros((y.size, 4))\n",
    "    onehot[np.arange(y.size),y] = 1\n",
    "    \n",
    "    train_X = itemgetter(*train_idx)(X)\n",
    "    train_y = itemgetter(*train_idx)(y)\n",
    "    \n",
    "    test_X = itemgetter(*test_idx)(X)\n",
    "    test_y = itemgetter(*test_idx)(y)\n",
    "    \n",
    "    return (train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = split(x, y)\n",
    "\n",
    "assert len(train_X) == len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "shuffled = list(zip(x, y))\n",
    "shuffle(shuffled)\n",
    "\n",
    "def batcherize(df):\n",
    "    for _ in range(epochs*10):\n",
    "        for features, labels in shuffled:\n",
    "            _features = np.array([features])\n",
    "            yield _features, np.atleast_1d(labels)\n",
    "        \n",
    "batcherize_train = batcherize(shuffled[:190])\n",
    "\n",
    "def batcherize_t():\n",
    "    for features, labels in shuffled[190:]:\n",
    "        _features = np.array([features])\n",
    "        yield _features, np.atleast_1d(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = tf.data.Dataset.from_generator(batcherize_t, output_types=(tf.float64, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(batcherize_train, batch_size=1, verbose=1, epochs=epochs, steps_per_epoch=190, validation_data=test_df, validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='Training')\n",
    "plt.plot(h.history['val_loss'], label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['accuracy'], label='Training')\n",
    "plt.plot(h.history['val_accuracy'], label='Test')\n",
    "plt.legend()"
   ]
  }
 ]
}