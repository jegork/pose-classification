{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n",
    "from operator import itemgetter \n",
    "from random import shuffle \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "y_list = []\n",
    "classes = ['kiss', 'handshake', 'hug', 'highfive']\n",
    "\n",
    "for class_n, c in enumerate(classes):\n",
    "    f = os.listdir('output/'+c)\n",
    "    f = list(map(lambda x: 'output/'+c+'/'+x, f))\n",
    "    \n",
    "    filtered = list(filter(lambda x: x.split('.')[-1] == 'npy', f))\n",
    "    filtered.sort(key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "    \n",
    "    #only use not-augmented videos\n",
    "    filtered = filtered[:50]\n",
    "    \n",
    "    y_list.extend([class_n]*len(filtered))\n",
    "    files.extend(filtered)\n",
    "\n",
    "y = np.array(y_list)\n",
    "\n",
    "x = [np.load(x)/255 for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[0].dtype)\n",
    "assert len(x) == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(X, y, test_size=0.1):\n",
    "    shuffled_idx = np.random.permutation(len(X))\n",
    "    \n",
    "    split_at = int(len(shuffled_idx) * test_size)\n",
    "    train_idx = shuffled_idx[split_at:]\n",
    "    test_idx = shuffled_idx[:split_at]\n",
    "    \n",
    "    #TODO: add use of one-hot encoding\n",
    "    onehot = np.zeros((y.size, 4))\n",
    "    onehot[np.arange(y.size),y] = 1\n",
    "    \n",
    "    train_X = itemgetter(*train_idx)(X)\n",
    "    train_y = itemgetter(*train_idx)(y)\n",
    "    \n",
    "    test_X = itemgetter(*test_idx)(X)\n",
    "    test_y = itemgetter(*test_idx)(y)\n",
    "    \n",
    "    return (train_X, test_X, train_y, test_y)\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = split(x, y)\n",
    "assert len(train_X) == len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 70\n",
    "shuffled = list(zip(x, y))\n",
    "shuffle(shuffled)\n",
    "\n",
    "def batcherize(df):\n",
    "    for _ in range(epochs):\n",
    "        for features, labels in shuffled:\n",
    "            _features = np.array([features])\n",
    "            yield _features, np.atleast_1d(labels)\n",
    "        \n",
    "batcherize_train = batcherize(shuffled[:180])\n",
    "\n",
    "def batcherize_t():\n",
    "    for features, labels in shuffled[180:]:\n",
    "        _features = np.array([features])\n",
    "        yield _features, np.atleast_1d(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Input(shape=(None, #N_FRAMES\n",
    "                     128, #WIDDTH\n",
    "                     128, #HEIGHT\n",
    "                     3), dtype='float')\n",
    "cnn_base = VGG16(input_shape=(128,\n",
    "                              128,\n",
    "                              3),\n",
    "                 weights=\"imagenet\",\n",
    "                 include_top=False)\n",
    "cnn_out = GlobalAveragePooling2D()(cnn_base.output)\n",
    "\n",
    "cnn = Model(cnn_base.input, cnn_out)\n",
    "cnn.trainable = False\n",
    "\n",
    "encoded_frames = TimeDistributed(cnn)(video)\n",
    "encoded_sequence = LSTM(256)(encoded_frames)\n",
    "hidden_layer = Dense(512, activation=\"relu\")(encoded_sequence)\n",
    "hidden_layer = Dense(256, activation=\"relu\")(hidden_layer)\n",
    "outputs = Dense(4, activation=\"softmax\")(hidden_layer)\n",
    "model = Model([video], outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =tf.keras.optimizers.Nadam(learning_rate=0.002,\n",
    "                  beta_1=0.9,\n",
    "                  beta_2=0.999,\n",
    "                  epsilon=1e-08,\n",
    "                  schedule_decay=0.004)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "\n",
    "test_df = tf.data.Dataset.from_generator(batcherize_t, output_types=(tf.float64, tf.int64))\n",
    "\n",
    "h = model.fit(\n",
    "    batcherize_train, \n",
    "    batch_size=1, \n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=180, \n",
    "    validation_data=test_df, \n",
    "    validation_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16,4))\n",
    "\n",
    "ax[0].plot(h.history['loss'], label='Training')\n",
    "ax[0].plot(h.history['val_loss'], label='Test')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Categorical Crossentropy')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(h.history['accuracy'], label='Training')\n",
    "ax[1].plot(h.history['val_accuracy'], label='Test')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "fig.savefig('./graphs/vgg/vgg_loss_accuracy.png', bbox_inches='tight', pad_inches=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df, steps=20)\n",
    "\n",
    "y_true = []\n",
    "\n",
    "y_true = list(map(lambda x: int(x[1]), list(batcherize_t())))\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "conf_m = sns.heatmap(tf.math.confusion_matrix(y_true, y_pred), annot=True, xticklabels=classes, yticklabels=classes)\n",
    "conf_m.set(xlabel='Predicted labels', ylabel='True labels')\n",
    "\n",
    "g.figure.savefig('./graphs/vgg/vgg_confusion_matrix.png', dpi=150, bbox_inches = \"tight\")"
   ]
  }
 ]
}